---
title: "My title"
author: "Bernice(Yixuan) Bao, Zheng(Zeb) Yang, Dongli Sun"
thanks: "Code and data are available at: <https://github.com/iloveyz12/US-Political-Support>."
date: "March 11, 2024"
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(palmerpenguins)
library(boot)
library(broom.mixed)
library(collapse)
library(dataverse)
library(gutenbergr)
library(janitor)
library(knitr)
library(marginaleffects)
library(modelsummary)
library(rstanarm)
library(tidybayes)
library(tidyverse)
library(arrow)
```


# Introduction

You can and should cross-reference sections and sub-sections. We use @citeR and @rohan.

The remainder of this paper is structured as follows. @sec-data....

We use the dataset from 2022 Cooperative Election Study @ces2022. To further enable the analysis I employed the use of the package of ggplot[@ggplot2] to generate histograms.

# Data {#sec-data}

```{r}
#| echo: false
#| warning: false
#| message: false
ces2022 <-
  read_csv(
    here::here("data/raw_data/ces2022.csv"),
    col_types =
      cols(
        "votereg" = col_integer(),
        "presvote20post" = col_integer(),
        "gender4" = col_integer(),
        "educ" = col_integer()
      )
  )

ces2022 <-
  ces2022 |>
  filter(votereg == 1,
         presvote20post %in% c(1, 2)) |>
  mutate(
    voted_for = if_else(presvote20post == 1, "Biden", "Trump"),
    voted_for = as_factor(voted_for),
    gender = case_when(
      gender4 == 1 ~ "Man", 
      gender4 == 2 ~ "Woman", 
      gender4 == 3 ~ "Non-binary", 
      gender4 == 4 ~ "Other"),
    education = case_when(
      educ == 1 ~ "No HS",
      educ == 2 ~ "High school graduate",
      educ == 3 ~ "Some college",
      educ == 4 ~ "2-year",
      educ == 5 ~ "4-year",
      educ == 6 ~ "Post-grad"
    ),
    education = factor(
      education,
      levels = c(
        "No HS",
        "High school graduate",
        "Some college",
        "2-year",
        "4-year",
        "Post-grad"
      )
    )
  ) |>
  select(voted_for, gender, education)
```






Talk more about it.





Talk way more about it. 



# Model

The goal of our modelling strategy is twofold. Firstly,


```{r}
#| echo: false
#| warning: false
#| message: false
#| include: false

set.seed(812)



ces2022_reduced <- 
  ces2022 |> 
  slice_sample(n = 1000)

political_preferences <-
  stan_glm(
    voted_for ~ gender + education,
    data = ces2022_reduced,
    family = binomial(link = "logit"),
    prior = normal(location = 0, scale = 2.5, autoscale = TRUE),
    prior_intercept = 
      normal(location = 0, scale = 2.5, autoscale = TRUE),
    seed = 812
  )

saveRDS(
  political_preferences,
  file = here::here("models/political_preference.rds")
)

```




## Model set-up

Define $y_i$ as the is the political preference of the respondent and equal to 1 if Biden and 0 if Trump. Then $\text{gender}_i$ is the gender of the respondent and $\text{education}_i$ is the highest education of the respondent.We could estimate the parameters using `stan_glm()`. Note that the model is a generally accepted short-hand. In practice `rstanarm` converts categorical variables into a series of indicator variables and there are multiple coefficients estimated. In the interest of run-time we will randomly sample 1,000 observations and fit the model on that, rather than the full dataset.

\begin{align} 
y_i|\pi_i &\sim \mbox{Bern}(\pi_i) \\
\mbox{logit}(\pi_i) &= \alpha + \beta_1 \times \mbox{gender}_i + \beta_2 \times \mbox{education}_i\\
\alpha &\sim \mbox{Normal}(0, 2.5) \\
\beta_1 &\sim \mbox{Normal}(0, 5.02) \\
\beta_2 &\sim \mbox{Normal}(0, 6.34)
\end{align}

We run the model in R [@citeR] using the `rstanarm` package of @rstanarm, `modelsummary` package of @modelsummary and `here` package of @here. We use the default priors from `rstanarm`.


### Model justification

We expect a positive relationship between .... In particular...

Binomial logistic regression is a statistical method used to model the probability of a binary outcome variable. It's particularly suitable for situations where the dependent variable has two categories, such as in this study where we examine the likelihood of respondents voting for either Biden or Trump based on their gender and education level. The decision to employ binomial logistic regression for our study stems from its suitability for modeling binary outcome variables. As the outcome variable pertains to respondents' voting behavior, which involves choosing between Biden or Trump, binomial logistic regression is well-suited to capture this dichotomous outcome.



# Results

Our results are summarized in @fig-vote.


```{r}
#| echo: false
#| warning: false
#| message: false
political_preferences <-
  readRDS(file = here::here("models/political_preference.rds"))
```

```{r}
#| label: tbl-vote
#| tbl-cap: "Whether a respondent is likely to vote for Biden based on their gender and education"
#| echo: false
#| warning: false
#| message: false
modelsummary(
  list(
    "Support Biden" = political_preferences
  ),
  statistic = "mad"
  )
```

Based on the table outlining the likelihood of respondents supporting Biden based on gender and education levels, several key insights emerge. Firstly, the intercept value of 0.791 suggests that there is a baseline level of support for Biden among the surveyed population, regardless of gender or education. For men, their coefficient is not explicitly listed in the table, but it's implicitly represented by the intercept value. In this case, the intercept value of 0.791 can be interpreted as the baseline level of support for Biden among men.

Conversely, for women, there is a direct coefficient provided in the table, which is -0.600. This negative coefficient suggests that women exhibit a slightly lower level of support for Biden compared to the baseline represented by men. When examining gender, it becomes evident that being non-binary has a significant negative impact on the likelihood of supporting Biden, with a coefficient of -24.685. This indicates a substantial decrease in support compared to other genders.   Conversely, the coefficient for individuals identifying as "Other" gender is negligible at 0.203, suggesting that this category does not significantly influence support for Biden.

The coefficients related to education levels illustrate a clear trend in support for Biden among respondents.High school graduates, individuals with some college education, and those with 2-year, 4-year, and post-graduate degrees all exhibit negative coefficients ranging from -0.492 to -1.640.Starting from high school graduates to post-graduates, there is a consistent decrease in support, with coefficients indicating diminishing likelihoods of supporting Biden as educational attainment increases. High school graduates exhibit a moderate decrease compared to the baseline, followed by individuals with some college education, 2-year, 4-year, and post-graduate degrees, showing progressively larger declines in support. Particularly striking is the substantial drop in support among those with post-graduate degrees, indicating that as education level increases, the likelihood of supporting Biden decreases.

Overall, the model's R-squared value of 0.057 indicates that gender and education levels explain only a small proportion of the variance in support for Biden among respondents.However, the coefficients provide valuable insights into how gender identity and educational attainment may influence political preferences, with non-binary gender and higher education levels being associated with decreased support for Biden.      Further analysis and exploration may be warranted to better understand the complex dynamics at play.


```{r}
#| label: fig-vote
#| fig-cap: "The distribution of presidential preferences, by gender, and highest education"
#| echo: false
#| eval: true
#| warning: false
#| message: false

ces2022 |>
  ggplot(aes(x = education, fill = voted_for)) +
  stat_count(position = "dodge") +
  facet_wrap(facets = vars(gender)) +
  theme_minimal() +
  labs(
    x = "Highest education",
    y = "Number of respondents",
    fill = "Voted for"
  ) +
  coord_flip() +
  scale_fill_manual(values = c("Trump" = "red", "Biden" = "blue")) +
  theme(legend.position = "bottom")
```



# Discussion

## First discussion point {#sec-first-point}



## Second discussion point

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included

\newpage

\appendix

# Appendix {-}


# Additional data details

# Model details {#sec-model-details}







\newpage


# References


